# qualiMLpy
This a repository collecting all metrics, algorithms and pieces of code related to data quality
for Machine Learning, developed by me and others at the MUDI lab (https://www.mudilab.net/mudi/) of
the DISCo dept. @ University of Milano-Bicocca.

The dependencies for all the code are: scikit-learn, numpy, scipy.

Some of our code has also been provisionally deployed in the form of web sandbox tools:

- Degree of correspondence: https://reprdeg-test.herokuapp.com/
- Degree of concordance: https://reliability-test.herokuapp.com/

You can find more information on most of these metrics in various articles:

* Cabitza, F., Campagner, A., & Sconfienza, L. M. (2020).
As if sand were stone. New concepts and metrics to probe the ground on which to build trustable AI.
BMC Medical Informatics and Decision Making, 20(1), 1-21.

* Cabitza, F., Campagner, A., Albano, D., et al. (2020).
The elephant in the machine: Proposing a new metric of data reliability and its application to a medical case to assess classification reliability.
Applied Sciences, 10(11), 4014.

* Campagner, A., Sconfienza, L., & Cabitza, F. (2020).
H-accuracy, an alternative metric to assess classification models in medicine.
Digital Personalized Health and Medicine; Studies in Health Technology and Informatics; IOS Press: Amsterdam, The Netherlands, 270.

